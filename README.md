# ğŸ§  Credit Risk Modeling â€“ AMEX Case Study

This project presents an end-to-end machine learning solution to predict **credit default risk**, using a real-world industrial-scale dataset provided by **American Express** as part of their Kaggle competition: [AMEX Default Prediction](https://www.kaggle.com/competitions/amex-default-prediction).

---

## ğŸ§­ Introduction

In the evolving landscape of consumer lending, accurately identifying creditworthy individuals is crucial for minimizing risk and maximizing customer satisfaction. This project leverages machine learning techniques to enhance credit default prediction, enabling financial institutions like **American Express** to offer credit products to the **right customers at the right time**.

By modeling customer behavior using **time-series transactional data** and anonymized profile information, we can build a more **robust, explainable, and high-performing model** that improves upon traditional risk models. This ensures better approval decisions, reduces potential losses, and ultimately **enhances the customer experience**.

ğŸ”— **Data Source:** [Kaggle Competition â€“ AMEX Default Prediction](https://www.kaggle.com/competitions/amex-default-prediction)

---

## ğŸ§  Key Contributions

- âœ… Handled a **large-scale dataset (5.5M+ rows)** with efficient chunking
- âœ… Performed **missing value treatment**, **categorical encoding**, and **temporal aggregation** over 12-month periods
- âœ… Engineered features like `mean`, `min`, `max`, and `last` for numeric time-series variables
- âœ… Applied **one-hot encoding** to categorical variables, generating 45+ new features
- âœ… Built and compared two models: **XGBoost** and a **Neural Network**, using extensive grid search
- âœ… Selected the final model based on **AUC performance** and **variance stability** across training and test splits
- âœ… Used **SHAP values** for model explainability and to understand feature contributions to risk prediction

---

## ğŸ“ Project Structure

```
ğŸ“¦ Credit_Risk_Modeling
 â”£ ğŸ“Š AMEX_Credit_Risk_Analysis.ipynb
 â”£ ğŸ“ˆ Credit Risk Model.pptx
 â”£ ğŸ§  credit_risk_modeling.py
 â”£ ğŸ“„ final_data_for_project.csv
 â”— ğŸ“˜ README.md
```

---

## ğŸ¯ Objective

To build an accurate and explainable credit risk model using machine learning that can challenge the existing production model used by American Express. The project implements two modeling strategies and selects the best based on AUC performance:

âœ… **XGBoost**  
ğŸ§ª **Neural Network**

---

## ğŸ“‚ Data Overview

- **Total Customers:** 91,783
- **Time Span:** 13 months of historical data
- **Categories of Features:**
  - `D_` - Delinquency
  - `B_` - Balance
  - `S_` - Spend
  - `P_` - Payment
  - `R_` - Risk

---

## âš™ï¸ Feature Engineering

- ğŸ“… Aggregated temporal features: `mean`, `min`, `max`, `last` over 12 months
- ğŸ·ï¸ One-hot encoded 11 categorical columns â†’ 45 dummy variables
- ğŸ§¼ Missing values handled based on type:
  - Binary â†’ 0
  - Categorical â†’ Mode
  - Numeric â†’ Mean

---

## ğŸ§ª Model Training

### 1ï¸âƒ£ XGBoost
- Grid search on:
  - Trees: 50, 100, 300
  - Learning rates: 0.01, 0.1
  - Row subsample: 50%, 80%
  - Feature subsample: 50%, 100%
  - Class weight: 1, 5, 10
- âœ… **72 models trained**
- ğŸ“ˆ **Best AUC performance on Test 2**
- ğŸ’¡ SHAP analysis used for model interpretability

### 2ï¸âƒ£ Neural Network
- Outliers capped to 99th percentile
- Normalized using `StandardScaler`
- Grid search on:
  - Hidden layers: 2, 4
  - Neurons: 4, 6
  - Activation: ReLU, Tanh
  - Dropout: 50%, 100%
  - Batch size: 100, 10000
- Trained 32 models
- âŒ Did **not outperform** XGBoost

---

## ğŸ“Š SHAP Value Insights (XGBoost)

| Feature       | Impact     |
|---------------|------------|
| `P_2_last`    | Negative   |
| `B_1_last`    | Negative   |
| `D_39_max`    | Positive   |
| `S_3_mean`    | Positive   |

SHAP values helped explain **how each feature contributes** to a prediction.

---

## ğŸ† Final Model Selection

- âœ… **XGBoost outperformed NN** across all sets (Train, Test1, Test2)
- Highest AUC with lowest variance
- Chosen as the final model for production-ready implementation

---

## ğŸš€ Future Enhancements

- Streamlit dashboard for real-time scoring
- AutoML model comparison
- Model monitoring for drift detection

---

## ğŸ“ˆ Results Summary

| Model         | AUC (Test2) | Remarks                       |
|---------------|-------------|-------------------------------|
| XGBoost       | âœ… High     | Best performer overall        |
| Neural Net    | Moderate    | Underperformed                |

---

## ğŸ›  Tech Stack

- Python, Pandas, NumPy
- Matplotlib, Seaborn
- LightGBM, XGBoost, Scikit-Learn
- SHAP, GridSearchCV
- PowerPoint for stakeholder communication

---

## ğŸ“£ Let's Connect

For questions, improvements, or collaboration, feel free to reach out or fork the repo!

